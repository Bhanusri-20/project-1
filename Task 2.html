from bs4 import BeautifulSoup
import requests
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
# Step 1: Crawl and Scrape Content from a Single URL
def scrape_website(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    # Extract meaningful content
    paragraphs = [p.text.strip() for p in soup.find_all('p') if p.text.strip()]
    headers = [h.text.strip() for h in soup.find_all(['h1', 'h2', 'h3']) if h.text.strip()]
    content = headers + paragraphs  # Combine headers and paragraphs

    # Combine and return as chunks
    chunks = [content[i:i+5] for i in range(0, len(content), 5)]  # Chunking
    return [' '.join(chunk) for chunk in chunks]
# Step 2: Generate Embeddings
def generate_embeddings(chunks):
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(chunks)
    return embeddings, model
# Step 3: Store Embeddings in FAISS Vector Database
def store_embeddings(embeddings):
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)  # Add embeddings to the FAISS index
    return index
# Step 4: Query Handling
def query_website(index, query, model, chunks, top_k=3):
    query_embedding = model.encode([query])
    distances, indices = index.search(query_embedding, top_k)
    # Ensure valid indices
    valid_results = [(chunks[i], distances[0][idx]) for idx, i in enumerate(indices[0]) if i < len(chunks)]
    return valid_results
# Step 5: Generate a Single Response
def generate_response(query, results):
    if not results:
        return f"No relevant results found for your query: {query}"
    # Format the top results
    response = f"Results for your query '{query}':\n\n"
    for i, (res, score) in enumerate(results, 1):
        response += f"Result {i} (Score: {score:.2f}):\n{res}\n\n"
    return response
# Example Usage
if _name_ == "_main_":
    # Single URL to crawl
    url = "https://www.stanford.edu/"  # Replace with your desired URL
    # Scrape and process the website
    print(f"Scraping {url}...")
    chunks = scrape_website(url)
    # Generate embeddings
    print("Generating embeddings...")
    embeddings, model = generate_embeddings(chunks)
    # Store embeddings in FAISS
    print("Storing embeddings in FAISS...")
    index = store_embeddings(embeddings)
    # Query the system
    query = input("please enter your query: ")
    top_k = 3  # Number of results to retrieve
    results = query_website(index, query, model, chunks, top_k=top_k)
    # Generate a response
    print("Generating response...")
    response = generate_response(query, results)
    print(response)